{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wolf\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import re\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLUMPS\n",
    "#### - `GitHub repo`: https://github.com/broadinstitute/getzlab-CLUMPS2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 main tasks from the `CLUMPS` algorithm\n",
    "- _(task 0) **localization** : localization_\n",
    "- **prep** : pre-processing\n",
    "- **run** : core clumps algorithm\n",
    "- **post** : post-processing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0) LOCALIZATION task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding af_dir, prot2af_chunks\n",
    "clumpsLocalization_results = {'cancer_genes': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/cancer_genes/allCancerGenes.txt', \n",
    "                              'coverage_track': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/coverage_track/WEx_cov.fwb', \n",
    "                              'coverage_track_index': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/coverage_track_index/WEx_cov.fwi', \n",
    "                              'fasta': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/fasta/UP000005640_9606.fasta.gz', \n",
    "                              'genome_2bit': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/genome_2bit/hg19.2bit',  \n",
    "                              'gpmaps': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/gpmaps/genomeProteomeMaps.txt', \n",
    "                              'maf': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/maf/pancan15k.v18.maf', \n",
    "                              'pdb_dir': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/pdb_dir/pdb', \n",
    "                              'af_dir' : 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/af_dir',\n",
    "                              'prot2pdb_chunks': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/prot2pdb_chunks/huniprot2pdb.run18_chunks', \n",
    "                              'prot2af_chunks': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/mnt/nfs/ro_disks/canine-b7f9872002626d1a514fcdf5e295a8bd/prot2AF_chunks/prot2af_00000.gz',\n",
    "                              'uniprot_map': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/uniprot_map/huniprot2pdb.run18.filt.txt', \n",
    "                              'small_maf': 'rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd/small_maf/pancan100.test.maf'}\n",
    "\n",
    "docker_image = 'gcr.io/broad-getzlab-workflows/adunford_clumps_highertimeout:latest'\n",
    "run_name = \"clumps_full_2hrtimeout_100kmax\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) PREP task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clumps_prep_task(wolf.Task):\n",
    "    # the pre-processing step which prepares input for clumps ('run step')\n",
    "    # Preparation for clumps input files:\n",
    "    # computes mutational frequencies, spectra, and identifies protein structures needed\n",
    "    resources = { \"mem\" : \"8G\" }\n",
    "    \n",
    "    name = \"%s_pre-processing_task\" % run_name\n",
    "    \n",
    "    # input data for the 'prep' step is the mutation annotation file (maf)\n",
    "    # <Required> Input file for CLUMPS. Default expects .maf\n",
    "    inputs = {\n",
    "        \"maf\" : None,\n",
    "        \"genome_2bit\" : None,\n",
    "        \"fasta\" : None, \n",
    "        \"gpmaps\" : None\n",
    "#         \"maf\" : localization[\"maf\"], # downstream task inputs are outputs from the localizaton task\n",
    "#         \"genome_2bit\" : localization[\"genome_2bit\"],\n",
    "#         \"fasta\" : localization[\"fasta\"],\n",
    "#         \"gpmaps\" : localization[\"gpmaps\"]\n",
    "    }\n",
    "    \n",
    "    \n",
    "    ### bash script to run the `prep-step` ###\n",
    "    # first look for the output directory and create it if it does not already exist\n",
    "    # take the input mutation data (maf)\n",
    "    # run the clumps-prep step\n",
    "    script = \"\"\"\n",
    "    mkdir clumps_preprocess\n",
    "    clumps-prep --input ${maf} --output_dir clumps_preprocess --hgfile ${genome_2bit} --fasta ${fasta} --gpmaps ${gpmaps}\n",
    "    tar cf clumps_preprocess.tar clumps_preprocess\n",
    "    \"\"\"\n",
    "    \n",
    "    # place the files from the 'clumps-prep' step into the output directory\n",
    "    output_patterns = {\n",
    "        \"prep_outdir\" : \"clumps_preprocess.tar\"\n",
    "    }\n",
    "    \n",
    "    # Docker images are specified as \"<image>[:tag]\". If [tag] is not given, it defaults to \"latest\"\n",
    "    docker = docker_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20220826-20:23:25] [prefect] Available disk storage at /mnt/nfs is small (149 GB remaining)\n",
      "[20220826-20:23:25] [prefect] Starting Slurm controller ...\n",
      "[20220826-20:23:26] [prefect] Waiting up to 60 seconds for Slurm controller to start ...\n",
      "[20220826-20:23:37] [prefect] Localizing inputs...\n",
      "[20220826-20:23:37] [prefect] Job staged on SLURM controller in: /mnt/nfs/workspace/clumps_full_2hrtimeout_100kmax_pre-processing_task__2022-06-16--20-16-15_ohy20dy_rgz4h0q_xurchlelmcp4c\n",
      "[20220826-20:23:37] [prefect] Preparing pipeline script\n",
      "[20220826-20:23:37] [prefect] 1/1 jobs avoided\n",
      "[20220826-20:24:04] [prefect] Terminating all jobs ... \n",
      "[20220826-20:24:04] [prefect] done\n"
     ]
    }
   ],
   "source": [
    "clumpsPrep = clumps_prep_task()\n",
    "clumpsPrep_results = clumpsPrep.run(\n",
    "    maf = clumpsLocalization_results[\"maf\"],\n",
    "    genome_2bit = clumpsLocalization_results[\"genome_2bit\"],\n",
    "    fasta = clumpsLocalization_results[\"fasta\"],\n",
    "    gpmaps = clumpsLocalization_results[\"gpmaps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pick the little chunk list I made.  May need to be a list.\n",
    "chunks_list = clumpsLocalization_results['prot2af_chunks'].replace('rodisk://canine-b7f9872002626d1a514fcdf5e295a8bd','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) RUN task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'clumps_af_300_gene_test'\n",
    "class clumps_run_task(wolf.Task):\n",
    "    # a scatter task to execute multiple runs of the same script in parallel\n",
    "    # we will parallelize this using ~300-400 chards\n",
    "    # this task is the main clumps processing/algorithm\n",
    "    resources = { \"mem\" : \"8G\" }\n",
    "    \n",
    "    name = \"%s_clumps_run_UniformSampler\" % run_name\n",
    "    \n",
    "    # the input files for this step are the different individual prot2pdb chunks from the huniprot2pdb_chunks folder\n",
    "    # provide a list of all the individual prot2pdb chunks (or the file path to each prot2pdb chunks file)\n",
    "    \n",
    "    # <Required> Directory of files titled with Uniprot IDs that have mutation information\n",
    "    # <Required> File mapping uniprot ID to PDB ID with residue-level mapping information.\n",
    "    # coverage_track is on the gs bucket\n",
    "    inputs = {\n",
    "        \"clumps_preprocess\" : None,\n",
    "        \"prot2pdb_chunks\" : None,\n",
    "        \"pdb_dir\" : None,\n",
    "        \"coverage_track\" : None,\n",
    "        \"coverage_track_index\" : None, # not actually used as an input; just needs to be localized alongside coverage_track\n",
    "        \"genome_2bit\" : None,\n",
    "        \"fasta\" : None,\n",
    "        \"gpmaps\" : None\n",
    "    }\n",
    "    \n",
    "    overrides = { \"prot2pdb_chunks\" : \"delayed\" }\n",
    "    \n",
    "    ### bash script to run the `run-step` ###\n",
    "    # un-tar the `clumps_preprocess.tar` file which is the output directory from the 'clumps-prep step'\n",
    "    # this will create a diretory(folder) of the same name (clumps_preprocess)\n",
    "    script = \"\"\"    \n",
    "    tar xf $clumps_preprocess\n",
    "    clumps --muts clumps_preprocess/split_proteins \\\n",
    "        --maps ${prot2pdb_chunks} \\\n",
    "        --mut_freq clumps_preprocess/mut_freq.txt \\\n",
    "        --out_dir clumps_results \\\n",
    "        --sampler UniformSampler \\\n",
    "        --coverage_track ${coverage_track} \\\n",
    "        --mut_spectra clumps_preprocess/mut_spectra.txt \\\n",
    "        --pdb_dir ${pdb_dir} \\\n",
    "        --hgfile ${genome_2bit} --fasta ${fasta} --gpmaps ${gpmaps} \\\n",
    "        --max_rand  10000  \\\n",
    "        --threads 32\n",
    "    \n",
    "    tar cf clumps_results.tar clumps_results\n",
    "\n",
    "    \"\"\"\n",
    "    output_patterns = {\n",
    "        \"run_outdir\" : \"clumps_results.tar\"\n",
    "    }\n",
    "    \n",
    "    # Docker Image\n",
    "    docker = docker_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20220826-20:44:36] [prefect] Available disk storage at /mnt/nfs is small (148 GB remaining)\n",
      "[20220826-20:44:36] [prefect] Starting Slurm controller ...\n",
      "[20220826-20:44:36] [prefect] Waiting up to 60 seconds for Slurm controller to start ...\n",
      "[20220826-20:44:45] [prefect] Cannot recover preexisting task outputs: [Errno 2] No such file or directory: '/mnt/nfs/workspace/clumps_af_300_gene_test_clumps_run_UniformSampler__2022-08-26--20-44-45_gpae3li_rgz4h0q_5fnitgoqlql5o/jobs/0'\n",
      "[20220826-20:44:45] [prefect] Overwriting output and aborting job avoidance.\n",
      "[20220826-20:44:45] [prefect] Localizing inputs...\n",
      "[20220826-20:44:45] [prefect] Job staged on SLURM controller in: /mnt/nfs/workspace/clumps_af_300_gene_test_clumps_run_UniformSampler__2022-08-26--20-44-45_gpae3li_rgz4h0q_5fnitgoqlql5o\n",
      "[20220826-20:44:45] [prefect] Preparing pipeline script\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clumpsRun = clumps_run_task()\n",
    "clumpsRun_results = clumpsRun.run(\n",
    "    clumps_preprocess = clumpsPrep_results[\"prep_outdir\"],\n",
    "    prot2pdb_chunks = chunks_list,\n",
    "    pdb_dir = clumpsLocalization_results[\"af_dir\"],\n",
    "    coverage_track = clumpsLocalization_results[\"coverage_track\"],\n",
    "    coverage_track_index = clumpsLocalization_results[\"coverage_track_index\"],\n",
    "    genome_2bit = clumpsLocalization_results[\"genome_2bit\"],\n",
    "    fasta = clumpsLocalization_results[\"fasta\"],\n",
    "    gpmaps = clumpsLocalization_results[\"gpmaps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/nfs/ro_disks/canine-b7f9872002626d1a514fcdf5e295a8bd/prot2AF_chunks/prot2af_00000.gz'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) POST-PROCESS task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clumps_postprocess_task(wolf.Task):\n",
    "    # Generates summary files from array outputs of clumps.\n",
    "    resources = { \"mem\" : \"8G\" }\n",
    "    name = '%s_postprocess' % (run_name)\n",
    "    inputs = {\n",
    "        \"clumps_preprocess\" : None,\n",
    "        \"clumps_results\" : None, # this is an array of directories, which in turn contain multiple files\n",
    "        \"cancer_genes\" : None,\n",
    "        \"uniprot_map\" : None,\n",
    "        \"pdb_dir\" : None\n",
    "    }\n",
    "    \n",
    "    script = \"\"\"\n",
    "    # gather contents of all clumps results directories into single directory\n",
    "    mkdir results_gather\n",
    "    cat ${clumps_results} | xargs -I{} find -L {} -type f -not -path \"*/.*\" | xargs -P100 -I{} ln -s {} results_gather\n",
    "    clumps-postprocess --input_dir results_gather \\\n",
    "      --proteins_dir ${clumps_preprocess}/split_proteins \\\n",
    "      --cancer_genes ${cancer_genes} \\\n",
    "      --uniprot_map ${uniprot_map} \\\n",
    "      --pdb_dir ${pdb_dir} \\\n",
    "      --output_file clumps_output.tsv\n",
    "    \"\"\"\n",
    "    \n",
    "    # Output file from CLUMPS with list of genes\n",
    "    output_patterns = {\n",
    "        \"clumps_output\" : \"clumps_output.tsv\"\n",
    "    }\n",
    "    \n",
    "    # Docker Image\n",
    "    docker = \"gcr.io/broad-getzlab-workflows/clumps:v55\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20220829-17:04:03] [prefect] Available disk storage at /mnt/nfs is small (146 GB remaining)\n",
      "[20220829-17:04:03] [prefect] Starting Slurm controller ...\n",
      "[20220829-17:04:03] [prefect] Waiting up to 60 seconds for Slurm controller to start ...\n",
      "[20220829-17:04:12] [prefect] Cannot recover preexisting task outputs: [Errno 2] No such file or directory: '/mnt/nfs/workspace/clumps_af_300_gene_test_postprocess__2022-08-29--17-04-12_cjnglma_2vzaanq_ttfqonvxt5xyg/jobs/0'\n",
      "[20220829-17:04:12] [prefect] Overwriting output and aborting job avoidance.\n",
      "[20220829-17:04:12] [prefect] Localizing inputs...\n",
      "[20220829-17:04:12] [prefect] Job staged on SLURM controller in: /mnt/nfs/workspace/clumps_af_300_gene_test_postprocess__2022-08-29--17-04-12_cjnglma_2vzaanq_ttfqonvxt5xyg\n",
      "[20220829-17:04:12] [prefect] Preparing pipeline script\n",
      "[20220829-17:08:14] [prefect] Finished with status FAILED\n",
      "[20220829-17:08:14] [prefect] Not all tasks were successful.\n",
      "[20220829-17:08:39] [prefect] Terminating all jobs ... \n",
      "[20220829-17:08:39] [prefect] done\n",
      "[20220829-17:09:00] [prefect] Not all Slurm jobs were successful\n"
     ]
    }
   ],
   "source": [
    "# THIS IS FOR TESTING\n",
    "# running the `post_task`\n",
    "clumpsPost = clumps_postprocess_task()\n",
    "clumpsPost_results = clumpsPost.run(\n",
    "    clumps_preprocess = clumpsPrep_results[\"prep_outdir\"],\n",
    "    clumps_results = [clumpsRun_results[\"run_outdir\"]],\n",
    "    cancer_genes = clumpsLocalization_results[\"cancer_genes\"],\n",
    "    uniprot_map = chunks_list,\n",
    "    #uniprot_map = clumpsLocalization_results[\"prot2af_chunks\"],\n",
    "    pdb_dir = clumpsLocalization_results[\"af_dir\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/nfs/workspace/clumps_full_2hrtimeout_100kmax_pre-processing_task__2022-06-16--20-16-15_ohy20dy_rgz4h0q_xurchlelmcp4c/outputs/0/prep_outdir/clumps_preprocess.tar'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clumpsPrep_results[\"prep_outdir\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) WORKFLOW\n",
    "using all 3 pre-defined taks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clumps_workflow(maf, genome_2bit, fasta, gpmaps, prot2pdb_chunks, pdb_dir, coverage_track, cancer_genes, uniprot_map):\n",
    "    # (step-#0): localization task\n",
    "    localization = wolf.localization.BatchLocalDisk(\n",
    "    # \"files\" parameter is a dict mapping output name -> file path\n",
    "      files = {\n",
    "        \"maf\" : maf,\n",
    "        \"genome_2bit\" : genome_2bit,\n",
    "        \"fasta\" : fasta,\n",
    "        \"gpmaps\" : gpmaps,\n",
    "        \"prot2pdb_chunks\" : prot2pdb_chunks,\n",
    "        \"pdb_dir\" : pdb_dir,\n",
    "        \"coverage_track\" : coverage_track,\n",
    "        \"cancer_genes\" : cancer_genes,\n",
    "        \"uniprot_map\" : uniprot_map\n",
    "      }\n",
    "    )\n",
    "    \n",
    "    # (step-#1): pre-processing \"prep\" task\n",
    "    clumps_prep = clumps_prep_task(\n",
    "        inputs = {\n",
    "            \"maf\" : localization[\"maf\"], # downstream task inputs are outputs from the localizaton task\n",
    "            \"genome_2bit\" : localization[\"genome_2bit\"],\n",
    "            \"fasta\" : localization[\"fasta\"],\n",
    "            \"gpmaps\" : localization[\"gpmaps\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # (step-#2): run task\n",
    "    clumps_run = clumps_run_task(\n",
    "        inputs = {\n",
    "            \"clumps_preprocess\" : clumps_prep[\"prep_outdir\"],\n",
    "            \"prot2pdb_chunks\" : chunks_list_18,\n",
    "            \"pdb_dir\" : pdb_dir,\n",
    "            \"coverage_track\" : localization[\"coverage_track\"],\n",
    "            \"genome_2bit\" : localization[\"genome_2bit\"],\n",
    "            \"fasta\" : localization[\"fasta\"],\n",
    "            \"gpmaps\" : localization[\"gpmaps\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # (step-#3): post-processing task\n",
    "    clumps_post = clumps_postprocess_task(\n",
    "        inputs = {\n",
    "            \"clumps_preprocess\" : clumps_prep[\"prep_outdir\"],\n",
    "            \"clumps_results\" : [clumps_run[\"run_outdir\"]], # gather_parameter (takes the outputs of the `run-step` as inputs),\n",
    "            \"cancer_genes\" : localization[\"cancer_genes\"],\n",
    "            \"uniprot_map\" : localization[\"uniprot_map\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Docker Image\n",
    "    # docker = \"gcr.io/broad-getzlab-workflows/clumps:v51\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) SUBMIT the job (run the workflow script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'prefect.engine' has no attribute 'executors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mwolf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWorkflow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkflow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclumps_workflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclust_frac\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommon_task_opts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mretry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# retry every task up to 5 times\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m clumps_analysis:\n\u001b[1;32m      6\u001b[0m     ca \u001b[38;5;241m=\u001b[39m clumps_analysis\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m      7\u001b[0m         maf \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://sa-clumps2-ref/dat/pancan15k.v18.maf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m         genome_2bit \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://sa-clumps2-ref/dat/hg19.2bit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         RUN_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclumps analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/wolf/workflow.py:52\u001b[0m, in \u001b[0;36mWorkflow.__init__\u001b[0;34m(self, backend, conf, workflow, context, common_task_opts)\u001b[0m\n\u001b[1;32m     45\u001b[0m \t\t\u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m \t\t  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe only acceptable overrides are \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     47\u001b[0m \t\t    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m k \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m override_keys])\n\u001b[1;32m     48\u001b[0m \t\t  )\n\u001b[1;32m     49\u001b[0m \t\t)\n\u001b[1;32m     50\u001b[0m \tcontext[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwolf_runner \u001b[38;5;241m=\u001b[39m \u001b[43mWolfRunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanine_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommon_context\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow_list \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/wolf/workflow.py:226\u001b[0m, in \u001b[0;36mWolfRunner.__init__\u001b[0;34m(self, flow, canine_backend, task_executor_cls, task_executor_kwargs, common_context, prehooks, posthooks)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_flow \u001b[38;5;241m=\u001b[39m flow\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_executor_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_task_executor_cls \u001b[38;5;241m=\u001b[39m \u001b[43mprefect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutors\u001b[49m\u001b[38;5;241m.\u001b[39mLocalDaskExecutor\n\u001b[1;32m    227\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_task_executor_kwargs \u001b[38;5;241m=\u001b[39m task_executor_kwargs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'prefect.engine' has no attribute 'executors'"
     ]
    }
   ],
   "source": [
    "with wolf.Workflow(\n",
    "    workflow = clumps_workflow,\n",
    "    conf = { \"clust_frac\" : 1 }, \n",
    "    common_task_opts = { \"retry\" : 5 } # retry every task up to 5 times\n",
    ") as clumps_analysis:\n",
    "    ca = clumps_analysis.run(\n",
    "        maf = \"gs://sa-clumps2-ref/dat/pancan15k.v18.maf\",\n",
    "        genome_2bit = \"gs://sa-clumps2-ref/dat/hg19.2bit\",\n",
    "        fasta = \"gs://sa-clumps2-ref/dat/UP000005640_9606.fasta.gz\",\n",
    "        gpmaps = \"gs://sa-clumps2-ref/dat/genomeProteomeMaps.txt\",\n",
    "        prot2pdb_chunks = chunks_list,\n",
    "        pdb_dir = pdb_dir,\n",
    "        coverage_track = \"gs://sa-clumps2-ref/dat/cov/WEx_cov.fwb\",\n",
    "        RUN_NAME = \"clumps analysis\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clumps_analysis.results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20220315-16:55:51] [prefect] Available disk storage at /mnt/nfs is small (53 GB remaining)\n",
      "[20220315-16:55:51] [prefect] Starting Slurm controller ...\n",
      "[20220315-16:55:51] [prefect] Waiting up to 60 seconds for Slurm controller to start ...\n",
      "[20220315-16:55:52] [prefect] Cannot recover preexisting task outputs: [Errno 2] No such file or directory: '/mnt/nfs/workspace/clumps_pre-processing_task__2022-03-15--16-55-52_ohy20dy_vtg5ndy_xurchlelmcp4c/jobs/0'\n",
      "[20220315-16:55:52] [prefect] Overwriting output and aborting job avoidance.\n",
      "[20220315-16:55:52] [prefect] Localizing inputs...\n",
      "[20220315-16:55:52] [prefect] Job staged on SLURM controller in: /mnt/nfs/workspace/clumps_pre-processing_task__2022-03-15--16-55-52_ohy20dy_vtg5ndy_xurchlelmcp4c\n",
      "[20220315-16:55:52] [prefect] Preparing pipeline script\n",
      "[20220315-17:47:13] [prefect] Finished with status COMPLETED\n",
      "[20220315-17:47:13] [prefect] Available disk storage at /mnt/nfs is small (52 GB remaining)\n",
      "[20220315-17:47:13] [prefect] Starting Slurm controller ...\n",
      "[20220315-17:47:13] [prefect] Waiting up to 60 seconds for Slurm controller to start ...\n",
      "[20220315-18:16:22] [prefect] Cannot recover preexisting task outputs: [Errno 2] No such file or directory: '/mnt/nfs/workspace/clumps_run_task__2022-03-15--18-16-22_twslosy_vtg5ndy_f0qsgrqan4zeq/jobs/0'\n",
      "[20220315-18:16:22] [prefect] Overwriting output and aborting job avoidance.\n",
      "[20220315-18:16:22] [prefect] Localizing inputs...\n",
      "[20220315-18:16:27] [prefect] Job staged on SLURM controller in: /mnt/nfs/workspace/clumps_run_task__2022-03-15--18-16-22_twslosy_vtg5ndy_f0qsgrqan4zeq\n",
      "[20220315-18:16:27] [prefect] Preparing pipeline script\n"
     ]
    }
   ],
   "source": [
    "# running the `prep_task` for full set, since set of 100 completed\n",
    "clumpsPrep = clumps_prep_task()\n",
    "clumpsPrep_results = clumpsPrep.run(\n",
    "    maf = clumpsLocalization_results[\"maf\"],\n",
    "    genome_2bit = clumpsLocalization_results[\"genome_2bit\"],\n",
    "    fasta = clumpsLocalization_results[\"fasta\"],\n",
    "    gpmaps = clumpsLocalization_results[\"gpmaps\"]\n",
    ")\n",
    "clumpsRun = clumps_run_task()\n",
    "clumpsRun_results = clumpsRun.run(\n",
    "    clumps_preprocess = clumpsPrep_results[\"prep_outdir\"],\n",
    "    prot2pdb_chunks = chunks_list_18,\n",
    "    pdb_dir = clumpsLocalization_results[\"pdb_dir\"],\n",
    "    coverage_track = clumpsLocalization_results[\"coverage_track\"],\n",
    "    coverage_track_index = clumpsLocalization_results[\"coverage_track_index\"],\n",
    "    genome_2bit = clumpsLocalization_results[\"genome_2bit\"],\n",
    "    fasta = clumpsLocalization_results[\"fasta\"],\n",
    "    gpmaps = clumpsLocalization_results[\"gpmaps\"]\n",
    ")\n",
    "clumpsPost = clumps_postprocess_task()\n",
    "clumpsPost_results = clumpsPost.run(\n",
    "    clumps_preprocess = clumpsPrep_results[\"prep_outdir\"],\n",
    "    clumps_results = [clumpsRun_results[\"run_outdir\"]],\n",
    "    cancer_genes = clumpsLocalization_results[\"cancer_genes\"],\n",
    "    uniprot_map = clumpsLocalization_results[\"uniprot_map\"],\n",
    "    pdb_dir = clumpsLocalization_results[\"pdb_dir\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
